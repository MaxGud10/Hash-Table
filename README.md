# Исследование работы хэш-таблицы с разрешением коллизий методом цепочек и ее низкоуровневая оптимизация

Гудчиков Максим, 1 курс ФРКТ МФТИ

[Хэш-таблица](https://khalilstemmler.com/blogs/data-structures-algorithms/hash-tables/) - это такая структура данных, в которой вставка, поиск и удаление элемента происходит за $O(1)$ в лучшем случае. Выглядит она так:
                                    
![Окно](img/example_hash_table.jpg)                                    


### Общий принцип ее работы

Общий принцип ее работы таков: пусть мы вставляем элемент в хеш-таблицу. Как выбирается ячейка хэш-таблицы, в которую нужно вставить элемент? На вход хэш-функции поступает ключ (в данном случае слово), из которого хэш-функция получает некое числовое значение. Это числовое значение и будет являться номером ячейки хэш-таблицы, в которую следует положить элемент. 

Для поиска и удаления алгоритм выбора ячейки хэш-таблицы такой же.

### Устройство нашей хэш-таблицы 

В качестве ячейки хэш-таблицы будет использоваться самописный двусвязный список, обладающий свойством локальности и дружественный к кешу. Сама хэш-таблица будет представлять из себя массив таких двусвязных списков. 

Иногда возникает проблема, когда хеш-функция выдает одинаковое натуральное число для разных элементов. Такая ситуация называется коллизией. Для решения этой проблемы в нашем проекте мы будем производить линейный поиск по соответствующему списку, что позволяет находить нужный элемент даже при коллизии.  

Ниже представлена картинка, которая отображает вышеизложенную информацию. 

![Окно](img/hashtable.png)

#### Функции нашей хэш-таблицы

Удаление элемента из хэш-таблицы нас интересовать не будет, такой функции поддерживаться не будет. 

Будет поддерживаться вставка и поиск элемента в хэш-таблице. 
В качестве элемента будет выступать слово. 

Вставка будет происходить таким образом, чтобы два одинаковых слова в хэш-таблице не встречалось (в одной ячейке не может быть два одинаковых слова). Следует уточнить, что значение, полученное хэш-функцией, может превосходить размер хэш-таблицы. Чтобы решить эту проблему, номер ячейки хэш-таблицы будет являться остатком от деления значения хэш-функции на размер хэш-таблицы.

Поиск элемента будет происходить по общему алгоритма поиска в хэш-таблице.


### Особенности системы

Тестирование на производительность выполнялось на процессоре **12th Gen Intel(R) Core(TM) i5-1200H**, который поддерживает SIMD инструкции AVX2 и ниже.
Это означает, что процессор может выполнять векторные инструкции над 256 битами данных одновременно. 

Характеристики:

|     Характеристика             |  Значение     | 
|--------------------------------|---------------|
| Тактовая частота               | 2.5 ГГц       |
| Количество ядер                | 12             |
| Количество потоков             | 16             |
| Кэш 1 уровня                   | 960 КБ (на ядро)  |
| Кэш 2 уровня                   | 7,5 МБ (на ядро)|
| Кэш 3 уровня                   | 18 МБ  (всего)     |

При этом все измерения будем проводить при одном и том же диапазоне температур процессора от 35 до 50 градусов цельсия и при подключённом зарядном устройстве.

> [!WARNING]
> Программа вовсе не скомпилируется, если ваш процессор не поддерживает SIMD инструкций стандарта AVX2. 

## Первая часть работы

### Цель

Цель первой части работы заключается в исследовании распределения значений восьми хэш-функций. Подробнее см. ниже.

### Метод исследования

Для исследования будем использовать нашу хэш-таблицу. В качестве данных для вставки в хэш-таблицу возьмем набор слов, использующихся в произведении У.Шекспира "Гамлет, принц датский" (см. [hamlet.txt](src/hamlet.txt)). Это позволит нам исследовать поведение хэш-функций не на искусственно сгенерированных данных, а на реальных, что лучше. После вставки всех слов в хэш-таблицу необходимо будет сделать дамп заселенности хэш-таблицы. Используя этот дамп, будем строить диаграмму заселенности хэш-таблицы.

Работать будем с лоад-фактором (или заселенностью) хэш-таблицы около 7. Это позволит нам лучше исследовать поведение хэш-функций, так как диапазон значений хэш-функций (в среднем) больше размера хэш-таблицы.

### Скрипт, считающий количество слов в тексте

Мой скрипт будет из текста делать файл, в котором на каждой строке будет находиться одно слово, при этом убирая различные знаки препинания. Важно отметить, что слова в выходном файле скрипта могут повторяться.

В текстовом файле, который создал мой скрипт из текста произведения У.Шекспира "Гамлет, принц датский", примерно 5500 уникальных слов.

### Размер хэш-таблицы

Стоит обговорить и размер хэш-таблицы. Ее размер должен быть простым числом. Почему? 

Допустим, что хэш-функция чаще всего выдает значения, кратные 100. Тогда в списках с индексами, кратными 100, будет в среднем больше элементов. Предположим, что размер хэш-таблицы будет также равен 100. Возьмем списки с номерами 200, 300, ... Остатки от деления номеров этих списков на размер хэш-таблицы будут совпадать. Следовательно, их элементы попадут в одну ячейку хэш-таблицы, и длина списка, соответствующего этой ячейке, будет равна сумме длин исходных списков. Поэтому в этой ячейке будет еще больше элементов, и на гистограмме будет усиливаться пик заселенности в этой ячейке. Строго говоря, усиление будет происходить для любых пиков, повторяющихся с периодом k, если у k и размера хэш-таблицы будет общий множитель. Чтобы минимизировать такую вероятность, размер хэш-таблицы стоит выбирать как простое число. Это позволит избежать усиления пиков заселенности.  

В нашем случае для того, чтобы лоад-фактор хэш-таблицы был $\simeq 7$, размер хэш-таблицы будет равен 787.

### Исследуемые хэш-функции

### Первая хэш-функция (`ConstHash()`)

Код первой хэш-функции выглядит так:

<details>
<summary> Показать код ConstHash</summary>

```c
uint32_t ConstHash (const HashTableElem_t value) 
{
    return 0;
}
```

То есть она всегда возвращает 0 вне зависимости от входной строки.
</details>

Диаграмма распределения такой хэш-функции:

![const_hash](img/ConstHash.png)

Дисперсия такого распределения:
```
Const hash:
variance of elements in hash table = 38213.79
```

Понятно, что эта функция никуда не годится.

### Вторая хэш-функция (`FirstSymHash()`)
                       
<details>
<summary>Код второй хэш-функции:</summary>

```c
uint32_t FirstSymHash (const HashTableElem_t value) 
{
   return ((int64_t) value[0]);
}
```

Она возвращает ASCII-код первой буквы слова. 
</details>


Диаграмма распределения такой хэш-функции:

![FirstSymHash](img/FirstSymHash.png)

Дисперсия такого распределения:
```
First symbol hash:
variance of elements in hash table = 1516.97
```

По сравнению с первой хэш-функцией уже лучше, однако такое распределение все так же никуда не годится.

### Третья хэш-функция (`LenHash()`)
<details>
<summary>Код третьей хэш-функции: </summary>

```c
uint32_t LenHash (const HashTableElem_t value) 
{
   return ((uint32_t) strlen (value));
}
```

Она возвращает длину слова.
</details>

Диаграмма распределения такой хэш-функции:

![len_hash](img/LenHash.png)

Видно, что значения 40 и более хэш-функция не возвращает, поэтому построим приближенную по оси x гистограмму: 

![len_hashSzoom](img/LenHash_zoom.png)

Дисперсия такого распределения:
```
Length hash:
variance of elements in hash table = 5136.29
```

Сильно неравномерная хэш-функция с ярко выраженным пиком в начале. Не стоит ее использовать. 

### Четвертая хэш-функция (`AsciiSumHash()`)

<details>
<summary>Код четвертой хэш-функции:</summary>

```c
uint32_t AsciiSumHash (const HashTableElem_t value) 
{

   uint32_t ascii_codes_sum = 0;
   uint32_t word_length     = (uint32_t) strlen (value);

   for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

   return ascii_codes_sum;
}
```
Она возвращает сумму всех ASCII-кодов слова.
</details>

Исследование этой хэш-функции будет производиться в двух случаях: 
1. При размере хэш-таблицы = 787;
2. При размере хэш-таблицы = 101.

#### Часть 1

Исследование при лоад-факторе хэш-таблицы $\simeq 7$.

Диаграмма распределения такой хэш-функции:

![ascii_sum_787](img/AsciiSumHash_787.png)

Дисперсия такого распределения:
```
Ascii sum hash, load factor ~= 7:
variance of elements in hash table = 33.95 
```

Отличная хэш-функция, судя по дисперсии. Но если обратить внимание на пики, то отличной ее назвать язык не повернется. Но самое главное, что эта функция коварна: она ограничена сверху, так как не существует таких длинных слов с большой суммой. Это приводит к тому, что теряется главное свойство хэш-таблицы: увеличивая ее размер, мы уменьшаем лоад-фактор и ускоряем поиск. Масштабирование по размеру в данном случае невозможно. 

#### Часть 2

Исследование при размере хэш-таблицы = 101.

Диаграмма распределения такой хэш-функции:

![101_ascii_hash](img/AsciiSumHash_101.png)    

Дисперсия такого распределения:
```
Ascii sum hash, hash table capacity = 101:
variance of elements in hash table = 463.25 
```

Распределение не совсем равномерное, но лучше всех рассмотренных выше хэш-функций. Ее можно было бы использовать для хэш-таблиц размером до ~100 ячеек, но из-за гигантского лоад-фактора хэш-таблицы лучше не использовать эту хэш-функцию.

### Пятая хэш-функция (`AsciiSumDivLenHash()`)
                      
<details>
<summary>Код пятой хэш-функции: </summary>

```c
uint32_t AsciiSumDivLenHash (const HashTableElem_t value) 
{
   uint32_t ascii_codes_sum = 0;

   uint32_t word_length     = (uint32_t) strlen (value);

   for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

   return ((uint32_t) (ascii_codes_sum / word_length));
}
```

Она возвращает округленный до целого результат деления суммы всех ASCII-кодов слова на длину слова.
</details>

Диаграмма распределения такой хэш-функции:

![ascii_sum_div_len_hash](img/AsciiSumDivLenHash.png)

Дисперсия такого распределения:
```
Ascii sum div len hash:
variance of elements in hash table = 2597.03 
```

Видно, что эта хэш-функция обладает ярко выраженным пиком и далеко не равномерным распределением. Не стоит ее использовать.

### Шестая хэш-функция (`RorHash()`)

<details>
<summary>Код шестой хэш-функции: </summary>

```c
uint32_t RorHash (const HashTableElem_t value) 
{
   uint32_t word_length = (uint32_t) strlen (value);

   if (word_length == 0)
        return 0;

   uint32_t hash = value[0];

   for (size_t i = 1; i <= word_length; i++)
   {

        hash = MyRor (hash, 1);
        hash ^= value[i];
   }

   return hash;
}
```

`MyRor()` - функция, выполняющая циклический побитовый сдвиг вправо. Так, например, `MyRor(a, b)` выполнит циклический сдвиг вправо на `b` позиций над числом `a` и вернет получившееся число.
</details>

Диаграмма распределения такой хэш-функции:

![ror_hash](img/RorHash.png)

Хэш-функция обладает не очень равномерным распределением. В принципе, использовать ее можно, но можно найти вариант лучше. 

Дисперсия такого распределения:
```
Ror hash:
variance of elements in hash table = 21.34  
```

### Седьмая хэш-функция (`RolHash()`)

Код седьмой хэш-функции ничем не отличается от шестой за исключением того, что вместо `MyRor` в ней используется `MyRol`:

<details>
<summary>Код шестой хэш-функции: </summary>

```c
uint32_t RolHash (const HashTableElem_t value) 
{
   uint32_t word_length = (uint32_t) strlen (value);

   if (word_length == 0)
        return 0;

   uint32_t hash = value[0];

   for (size_t i = 1; i <= word_length; i++) 
   {

        hash = MyRol (hash, 1);
        hash ^= value[i];
   }

   return hash;
}
```

`MyRol()` - функция, выполняющая циклический побитовый сдвиг влево.
</details>

Диаграмма распределения такой хэш-функции:

![rol_hash](img/RolHash.png)

Распределение выглядит довольно равномерно, оно без особо ярко выраженных пиков. Функция пригодна к использованию в реальных задачах.  

Дисперсия такого распределения:
```
Rol hash:
variance of elements in hash table = 8.89   
```


### _Интересный факт про оптимизацию `MyRol()` и `MyRor()`_

Оказывается, функции `MyRor()` и `MyRol()` компилятор при любом флаге оптимизации может свернуть в ассемблерные команды ror и rol соответственно [(пример для -O3)](https://godbolt.org/z/7evqzfPMc):

![окно](img/ror_rol_03.png)

### Восьмая хэш-функция (`MurmurHash()`)

В качестве восьмой хэш-функции будет выступать MurmurHash3_32. Сид у такой хэш-функции будет постоянен и равен 0.

<details>
<summary>Код этой хэш-функции: </summary>

```c
uint32_t MurmurHash (const HashTableElem_t value) 
{
   const uint8_t *key  = (const uint8_t *) value;

   const uint32_t len  = (size_t) strlen ((char *) key);

   uint32_t hash             = 0;
   uint32_t four_bytes_block = 0;

   for (uint32_t i = len / 4; i > 0; i--) 
   {
      memcpy (&four_bytes_block, key, sizeof (uint32_t));

      key += sizeof (uint32_t);

      four_bytes_block *= MAGIC_NUM_1;
      four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
      four_bytes_block *= MAGIC_NUM_2;

      hash ^= four_bytes_block;
      hash  = MyRol (hash, MAGIC_NUM_FOR_ROL_2);
      hash  = hash * MAGIC_NUM_6 + MAGIC_NUM_3;
   }

   four_bytes_block = 0;

   for (uint32_t i = len % 4; i > 0; i--) 
   {
      four_bytes_block <<= 8;
      four_bytes_block  |= key [i - 1];
   }

   four_bytes_block *= MAGIC_NUM_1;
   four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
   four_bytes_block *= MAGIC_NUM_2;

   hash ^= four_bytes_block;

   hash ^= len;

   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);
   hash *= MAGIC_NUM_4;
   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_2);
   hash *= MAGIC_NUM_5;
   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);

   return hash;
}
```
</details>

Диаграмма распределения такой хэш-функции:

![murmurhash](img/MurmurHash.png)

Хэш-функция показывает равномерное распределение и отсутствие пиков. Отличная хэш-функция для реальных задач.

Дисперсия такого распределения:
```
Murmur hash:
variance of elements in hash table = 6.93  
```

Можно заметить, что эта хэш-функция показывает лучшее распределение среди представленных в этой работе.


### Вывод о распределениях этих хэш-функций

Таблица дисперсий исследуемых хэш-функций:

| Хэш-функция           | Дисперсия           |
| :-------------------------: | :-----------------: |
| `ConstHash()`                              | $38214$  |
| `LenHash()`                                | $5136$  |
| `AsciiSumDivLenHash()`                     | $2597$  |
| `FirstSymHash()`                           | $1517$  |
| `AsciiSumHash()`, размер хэш-таблицы = 101 | $463.3$  |
| `AsciiSumHash()`, лоад-фактор ~= 7         | $33.95$           |
| `RorHash()`                                | $21.34$           |
| `RolHash()`                                | $8.89$           |
| `MurmurHash()`                             | $6.93$           |

Видно, что `ConstHash()` надо использовать ... примерно никогда. Дисперсия этой хэш-функции очень велика, и поиск в хэш-таблице будет выполняться очень медленно. Между тем, `MurmurHash()` показал наименьший результат по дисперсии. Это означает, что эта хэш-функция отлично подходит для ее применении в хэш-таблицах.



## Вторая часть работы

### Цель

Во второй части работы необходимо оптимизировать поиск по хэш-таблице (сделать его быстрее). Необходимо сделать как минимум 3 оптимизации, используя 3 разных инструмента:
- встроенный в C ассемблер;
- внешний ассемблер;
- intrinsic функции.

Производительность до и после оптимизаций будем замерять как профилировщиком, так и функцией `rdtsc()` (речь об этом пойдет ниже). Замеры будут производиться 3 раза для получение более точного результата и выяснения влияние погрешности на эти замеры.

В качестве компиляторов будут использоваться GCC версии 13.3.0 и CLANG версии 18.

### Замеры производительности

В качестве средства профилирования будет использоваться **hotspot** — графический интерфейс для Linux **perf** 

| Команда                            | Описание                         |
|------------------------------------|----------------------------------|
| make hotspot                       | Запуск проекта с hotspot        |
| make perf-report                   | Консольный отчет perf           |
| make profile-gprof                 | Альтернативное профилирование (gprof) |
| make profile-valgrind              | Альтернативное профилирование (valgrind) |
| make rebuild                       | Обычная сборка                  |


<!-- Чтобы запустить проект с **hotspot**:
```bash
   make hotspot
```
Чтобы посмотреть консольный отчет perf
```bash
   make perf-report
```

Альтернативное профилирование
```bash
   make profile-gprof  # или profile-valgrind
```                                          

Обычная сборка
```bash
make rebuild
``` -->

Помимо этого, для замера производительности также будет использоваться `rdtsc()`. Она возвращает число тактов, прошедших с момента последнего сброса процессора. Функция `rdtsc()` до начала бенчмарка и сразу после него:

```c
int64_t cycle_start = __rdtsc();
 
HashTableFindBenchmark (&hash_table, &words_from_file);

int64_t cycle_end = __rdtsc();
```

Таким образом, мы сможем получить количество циклов, затраченных на бенчмарк. Сам бенчмарк будет производиться так: все слова, которые находятся в хэш-таблице, будут искаться 20000 раз:

```c
for (size_t i = 0; i < MAX_BENCHMARK_COMP_NUM; i++) { // 20000 iterations

    char *volatile curr_word = (words -> word);

    for (size_t word_num = 0; word_num < ((size_t) words -> num_of_words); word_num++) {

        HashTableFind (hash_table, curr_word);
        curr_word += MAX_WORD_LENGTH;
    }
}
```

Многократный поиск слов позволит снизить влияние внешних факторов (системные прерывания, различные случайные промахи) на случайную погрешность времени бенчмарка.

### Сравнение GCC и CLANG

По ходу работы будем сравнивать скорость кода, который генерирует GCC и GLANG с помощью нашего бенчмарка. Для этого будем делать 2 таблицы с измерениями. В одной таблице будет производительность кода, сгенерированным GCC, в другой - сгенерированным CLANG. 


### Насчет троттлинга

Если во время бенчмарка начался троттлинг, то результаты измерений с помощью `rdtsc()` на самом деле недостоверны. Чтобы избежать пропуска тактов из-за перегрева процессора, возможное появление троттлинга во время бенчмарка будем отслеживать с помощью программы AIDA64.

По данным с сайта [Intel](https://www.intel.com/content/www/us/en/products/sku/65707/intel-core-i53317u-processor-3m-cache-up-to-2-60-ghz/specifications.html), 105°C - это температура нашего процессора, выше которой кристалл умирает. На самом деле, троттлинг начинается с температуры 100°C. Будем следить, чтобы такая температура не достигалась при бенчмарке.

---

### Производительность до оптимизаций

Замерим производительность бенчмарком до различных оптимизаций. 

Результаты измерений скорости кода, сгенерированным GCC:

| Номер измерения | Затрачено циклов       |
| :-------------: | :--------------------: |
| 1               | $1.48 \cdot 10^{11}$ |
| 2               | $1.57 \cdot 10^{11}$ |
| 3               | $1.54 \cdot 10^{11}$ |

Среднее число затраченных циклов = $1.53 \cdot 10^{11}$. Погрешность среднего составляет $2.66 \cdot 10^9$. Видно, что погрешность составляет $\approx 2\%$. Заметим, что троттлинга во время теста не наблюдалось:
