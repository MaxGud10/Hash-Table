# Исследование работы хэш-таблицы с разрешением коллизий методом цепочек и ее низкоуровневая оптимизация

Гудчиков Максим, 1 курс ФРКТ МФТИ

[Хэш-таблица](https://khalilstemmler.com/blogs/data-structures-algorithms/hash-tables/) - это такая структура данных, в которой вставка, поиск и удаление элемента происходит за $O(1)$ в лучшем случае. Выглядит она так:
                                    
![Окно](img/example_hash_table.jpg)                                    


### Общий принцип ее работы

Общий принцип ее работы таков: пусть мы вставляем элемент в хеш-таблицу. Как выбирается ячейка хэш-таблицы, в которую нужно вставить элемент? На вход хэш-функции поступает ключ (в данном случае слово), из которого хэш-функция получает некое числовое значение. Это числовое значение и будет являться номером ячейки хэш-таблицы, в которую следует положить элемент. 

Для поиска и удаления алгоритм выбора ячейки хэш-таблицы такой же.

### Устройство нашей хэш-таблицы 

В качестве ячейки хэш-таблицы будет использоваться самописный двусвязный список, обладающий свойством локальности и дружественный к кешу. Сама хэш-таблица будет представлять из себя массив таких двусвязных списков. 

**ПРИДУМАЙ КАРТИНКУ КОТОРУЮ МОЖНО ВСТАВИТЬ СЮДА**

#### Функции нашей хэш-таблицы

Удаление элемента из хэш-таблицы нас интересовать не будет, такой функции поддерживаться не будет. 

Будет поддерживаться вставка и поиск элемента в хэш-таблице. 
В качестве элемента будет выступать слово. 

Вставка будет происходить таким образом, чтобы два одинаковых слова в хэш-таблице не встречалось (в одной ячейке не может быть два одинаковых слова). Следует уточнить, что значение, полученное хэш-функцией, может превосходить размер хэш-таблицы. Чтобы решить эту проблему, номер ячейки хэш-таблицы будет являться остатком от деления значения хэш-функции на размер хэш-таблицы.

Поиск элемента будет происходить по общему алгоритма поиска в хэш-таблице.

## Первая часть работы

### Цель

Цель первой части работы заключается в исследовании распределения значений восьми хэш-функций. Подробнее см. ниже.

### Метод исследования

Для исследования будем использовать нашу хэш-таблицу. В качестве данных для вставки в хэш-таблицу возьмем набор слов, использующихся в произведении У.Шекспира "Гамлет, принц датский" (см. [hamlet.txt](src/hamlet.txt)). Это позволит нам исследовать поведение хэш-функций не на искусственно сгенерированных данных, а на реальных, что лучше. После вставки всех слов в хэш-таблицу необходимо будет сделать дамп заселенности хэш-таблицы. Используя этот дамп, будем строить диаграмму заселенности хэш-таблицы.

Работать будем с лоад-фактором (или заселенностью) хэш-таблицы около 7. Это позволит нам лучше исследовать поведение хэш-функций, так как диапазон значений хэш-функций (в среднем) больше размера хэш-таблицы.

### Скрипт, считающий количество слов в тексте

Мой скрипт будет из текста делать файл, в котором на каждой строке будет находиться одно слово, при этом убирая различные знаки препинания. Важно отметить, что слова в выходном файле скрипта могут повторяться.

В текстовом файле, который создал мой скрипт из текста произведения У.Шекспира "Гамлет, принц датский", примерно 5500 уникальных слов.

### Размер хэш-таблицы

Стоит обговорить и размер хэш-таблицы. Ее размер должен быть простым числом. Почему? 

Допустим, что хэш-функция чаще всего выдает значения, кратные 100. Тогда в списках с индексами, кратными 100, будет в среднем больше элементов. Предположим, что размер хэш-таблицы будет также равен 100. Возьмем списки с номерами 200, 300, ... Остатки от деления номеров этих списков на размер хэш-таблицы будут совпадать. Следовательно, их элементы попадут в одну ячейку хэш-таблицы, и длина списка, соответствующего этой ячейке, будет равна сумме длин исходных списков. Поэтому в этой ячейке будет еще больше элементов, и на гистограмме будет усиливаться пик заселенности в этой ячейке. Строго говоря, усиление будет происходить для любых пиков, повторяющихся с периодом k, если у k и размера хэш-таблицы будет общий множитель. Чтобы минимизировать такую вероятность, размер хэш-таблицы стоит выбирать как простое число. Это позволит избежать усиления пиков заселенности.  

В нашем случае для того, чтобы лоад-фактор хэш-таблицы был $\simeq 7$, размер хэш-таблицы будет равен 787.

### Исследуемые хэш-функции

### Первая хэш-функция (`ConstHash()`)

Код первой хэш-функции выглядит так:

<details>
<summary> Показать код ConstHash</summary>

```c
uint32_t ConstHash (const HashTableElem_t value) 
{
    return 0;
}
```

То есть она всегда возвращает 0 вне зависимости от входной строки.
</details>

Диаграмма распределения такой хэш-функции:

![const_hash](img/ConstHash().png)

Дисперсия такого распределения:
```
Const hash:
variance of elements in hash table = 38213.79
```

Понятно, что эта функция никуда не годится.

### Вторая хэш-функция (`FirstSymHash()`)
                       
<details>
<summary>Код второй хэш-функции:</summary>

```c
uint32_t FirstSymHash (const HashTableElem_t value) 
{
   return ((int64_t) value[0]);
}
```

Она возвращает ASCII-код первой буквы слова. 
</details>


Диаграмма распределения такой хэш-функции:

![FirstSymHash](img/FirstSymHash().png)

Дисперсия такого распределения:
```
First symbol hash:
variance of elements in hash table = 1516.97
```

По сравнению с первой хэш-функцией уже лучше, однако такое распределение все так же никуда не годится.

### Третья хэш-функция (`LenHash()`)
<details>
<summary>Код третьей хэш-функции: </summary>

```c
uint32_t LenHash (const HashTableElem_t value) 
{
   return ((uint32_t) strlen (value));
}
```

Она возвращает длину слова.
</details>

Диаграмма распределения такой хэш-функции:

![len_hash](img/LenHash().png)

Видно, что значения 40 и более хэш-функция не возвращает, поэтому построим приближенную по оси x гистограмму: 

![len_hashSzoom](img/LenHash()_zoom.png)

Дисперсия такого распределения:
```
Length hash:
variance of elements in hash table = 5136.29
```

Сильно неравномерная хэш-функция с ярко выраженным пиком в начале. Не стоит ее использовать. 

### Четвертая хэш-функция (`AsciiSumHash()`)

<details>
<summary>Код четвертой хэш-функции:</summary>

```c
uint32_t AsciiSumHash (const HashTableElem_t value) 
{

   uint32_t ascii_codes_sum = 0;
   uint32_t word_length     = (uint32_t) strlen (value);

   for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

   return ascii_codes_sum;
}
```
Она возвращает сумму всех ASCII-кодов слова.
</details>

Исследование этой хэш-функции будет производиться в двух случаях: 
1. При размере хэш-таблицы = 787;
2. При размере хэш-таблицы = 101.

#### Часть 1

Исследование при лоад-факторе хэш-таблицы $\simeq 7$.

Диаграмма распределения такой хэш-функции:

![ascii_sum_787](img/AsciiSumHash()_787.png)

Дисперсия такого распределения:
```
Ascii sum hash, load factor ~= 7:
variance of elements in hash table = 33.95 
```

Отличная хэш-функция, судя по дисперсии. Но если обратить внимание на пики, то отличной ее назвать язык не повернется. Но самое главное, что эта функция коварна: она ограничена сверху, так как не существует таких длинных слов с большой суммой. Это приводит к тому, что теряется главное свойство хэш-таблицы: увеличивая ее размер, мы уменьшаем лоад-фактор и ускоряем поиск. Масштабирование по размеру в данном случае невозможно. 

#### Часть 2

Исследование при размере хэш-таблицы = 101.

Диаграмма распределения такой хэш-функции:

![101_ascii_hash](img/AsciiSumHash()_101.png)    

Дисперсия такого распределения:
```
Ascii sum hash, hash table capacity = 101:
variance of elements in hash table = 463.25 
```

Распределение не совсем равномерное, но лучше всех рассмотренных выше хэш-функций. Ее можно было бы использовать для хэш-таблиц размером до ~100 ячеек, но из-за гигантского лоад-фактора хэш-таблицы лучше не использовать эту хэш-функцию.

### Пятая хэш-функция (`AsciiSumDivLenHash()`)
                      
<details>
<summary>Код пятой хэш-функции: </summary>

```c
uint32_t AsciiSumDivLenHash (const HashTableElem_t value) 
{
   uint32_t ascii_codes_sum = 0;

   uint32_t word_length     = (uint32_t) strlen (value);

   for (size_t i = 0; i < word_length; i++)
        ascii_codes_sum += value[i];

   return ((uint32_t) (ascii_codes_sum / word_length));
}
```

Она возвращает округленный до целого результат деления суммы всех ASCII-кодов слова на длину слова.
</details>

Диаграмма распределения такой хэш-функции:

![ascii_sum_div_len_hash](img/AsciiSumDivLenHash().png)

Дисперсия такого распределения:
```
Ascii sum div len hash:
variance of elements in hash table = 2597.03 
```

Видно, что эта хэш-функция обладает ярко выраженным пиком и далеко не равномерным распределением. Не стоит ее использовать.

### Шестая хэш-функция (`RorHash()`)

<details>
<summary>Код шестой хэш-функции: </summary>

```c
uint32_t RorHash (const HashTableElem_t value) 
{
   uint32_t word_length = (uint32_t) strlen (value);

   if (word_length == 0)
        return 0;

   uint32_t hash = value[0];

   for (size_t i = 1; i <= word_length; i++)
   {

        hash = MyRor (hash, 1);
        hash ^= value[i];
   }

   return hash;
}
```

`MyRor()` - функция, выполняющая циклический побитовый сдвиг вправо. Так, например, `MyRor(a, b)` выполнит циклический сдвиг вправо на `b` позиций над числом `a` и вернет получившееся число.
</details>

Диаграмма распределения такой хэш-функции:

![ror_hash](img/RorHash().png)

Хэш-функция обладает не очень равномерным распределением. В принципе, использовать ее можно, но можно найти вариант лучше. 

Дисперсия такого распределения:
```
Ror hash:
variance of elements in hash table = 21.34  
```

### Седьмая хэш-функция (`RolHash()`)

Код седьмой хэш-функции ничем не отличается от шестой за исключением того, что вместо `MyRor` в ней используется `MyRol`:

<details>
<summary>Код шестой хэш-функции: </summary>

```c
uint32_t RolHash (const HashTableElem_t value) 
{
   uint32_t word_length = (uint32_t) strlen (value);

   if (word_length == 0)
        return 0;

   uint32_t hash = value[0];

   for (size_t i = 1; i <= word_length; i++) 
   {

        hash = MyRol (hash, 1);
        hash ^= value[i];
   }

   return hash;
}
```

`MyRol()` - функция, выполняющая циклический побитовый сдвиг влево.
</details>

Диаграмма распределения такой хэш-функции:

![rol_hash](img/RolHash().png)

Распределение выглядит довольно равномерно, оно без особо ярко выраженных пиков. Функция пригодна к использованию в реальных задачах.  

Дисперсия такого распределения:
```
Rol hash:
variance of elements in hash table = 8.89   
```


### _Интересный факт про оптимизацию `MyRol()` и `MyRor()`_

Оказывается, функции `MyRor()` и `MyRol()` компилятор при любом флаге оптимизации может свернуть в ассемблерные команды ror и rol соответственно [(пример для -O3)](https://godbolt.org/z/7evqzfPMc):

![окно](img/ror_rol_03.png)

### Восьмая хэш-функция (`MurmurHash()`)

В качестве восьмой хэш-функции будет выступать MurmurHash3_32. Сид у такой хэш-функции будет постоянен и равен 0.

<details>
<summary>Код этой хэш-функции: </summary>

```c
uint32_t MurmurHash (const HashTableElem_t value) 
{
   const uint8_t *key  = (const uint8_t *) value;

   const uint32_t len  = (size_t) strlen ((char *) key);

   uint32_t hash             = 0;
   uint32_t four_bytes_block = 0;

   for (uint32_t i = len / 4; i > 0; i--) 
   {
      memcpy (&four_bytes_block, key, sizeof (uint32_t));

      key += sizeof (uint32_t);

      four_bytes_block *= MAGIC_NUM_1;
      four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
      four_bytes_block *= MAGIC_NUM_2;

      hash ^= four_bytes_block;
      hash  = MyRol (hash, MAGIC_NUM_FOR_ROL_2);
      hash  = hash * MAGIC_NUM_6 + MAGIC_NUM_3;
   }

   four_bytes_block = 0;

   for (uint32_t i = len % 4; i > 0; i--) 
   {
      four_bytes_block <<= 8;
      four_bytes_block  |= key [i - 1];
   }

   four_bytes_block *= MAGIC_NUM_1;
   four_bytes_block  = MyRol (four_bytes_block, MAGIC_NUM_FOR_ROL_1);
   four_bytes_block *= MAGIC_NUM_2;

   hash ^= four_bytes_block;

   hash ^= len;

   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);
   hash *= MAGIC_NUM_4;
   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_2);
   hash *= MAGIC_NUM_5;
   hash ^= (hash >> MAGIC_NUM_FOR_BIT_SHIFT_1);

   return hash;
}
```
</details>

Диаграмма распределения такой хэш-функции:

![murmurhash](img/MurmurHash().png)

Хэш-функция показывает равномерное распределение и отсутствие пиков. Отличная хэш-функция для реальных задач.

Дисперсия такого распределения:
```
Murmur hash:
variance of elements in hash table = 6.93  
```

Можно заметить, что эта хэш-функция показывает лучшее распределение среди представленных в этой работе.


### Вывод о распределениях этих хэш-функций

Таблица дисперсий исследуемых хэш-функций:

| Хэш-функция           | Дисперсия           |
| :-------------------------: | :-----------------: |
| `ConstHash()`                              | $38214$  |
| `LenHash()`                                | $5136$  |
| `AsciiSumDivLenHash()`                     | $2597$  |
| `FirstSymHash()`                           | $1517$  |
| `AsciiSumHash()`, размер хэш-таблицы = 101 | $463.3$  |
| `AsciiSumHash()`, лоад-фактор ~= 7         | $33.95$           |
| `RorHash()`                                | $21.34$           |
| `RolHash()`                                | $8.89$           |
| `MurmurHash()`                             | $6.93$           |

Видно, что `ConstHash()` надо использовать ... примерно никогда. Дисперсия этой хэш-функции очень велика, и поиск в хэш-таблице будет выполняться очень медленно. Между тем, `MurmurHash()` показал наименьший результат по дисперсии. Это означает, что эта хэш-функция отлично подходит для ее применении в хэш-таблицах.
